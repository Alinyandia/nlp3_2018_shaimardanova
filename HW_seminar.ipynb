{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# По мотивам семинара:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/Users/alinashaymardanova/Desktop/3.1/Авто1/data/sentiment_twitter/train_sentiment_ttk.tsv', sep='\\t')\n",
    "test_data = pd.read_csv('/Users/alinashaymardanova/Desktop/3.1/Авто1/data/sentiment_twitter/test_sentiment_ttk.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CountVectorizer & LogisticRegression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "count_vectorizer.fit(train_data.text.values) \n",
    "\n",
    "X_train = count_vectorizer.transform(train_data.text.values)\n",
    "X_test = count_vectorizer.transform(test_data.text.values)\n",
    "\n",
    "y_train = train_data.label.values\n",
    "y_test = test_data.label.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_log = LogisticRegression(penalty=\"l1\", C=0.1)\n",
    "clf_log.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf_log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.69      0.59      0.64       902\n",
      "          0       0.61      0.80      0.69       972\n",
      "          1       0.30      0.03      0.06       180\n",
      "\n",
      "avg / total       0.62      0.64      0.61      2054\n",
      "\n",
      "Макросредняя F1 мера -  0.463064212113\n",
      "Микросредняя F1 мера -  0.638753651412\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print('Макросредняя F1 мера - ',f1_score(y_test, y_pred, average='macro'))\n",
    "print('Микросредняя F1 мера - ',f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TF-IDF & LogisticRegression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(train_data.text.values)\n",
    "\n",
    "X_train = tfidf.transform(train_data.text.values)\n",
    "X_test = tfidf.transform(test_data.text.values)\n",
    "\n",
    "y_train = train_data.label.values\n",
    "y_test = test_data.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_log = LogisticRegression(penalty='l1')\n",
    "clf_log.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf_log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.70      0.69      0.70       902\n",
      "          0       0.66      0.76      0.71       972\n",
      "          1       0.37      0.09      0.15       180\n",
      "\n",
      "avg / total       0.65      0.67      0.65      2054\n",
      "\n",
      "Макросредняя F1 мера -  0.517616688856\n",
      "Микросредняя F1 мера -  0.671372930867\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print('Макросредняя F1 мера - ',f1_score(y_test, y_pred, average='macro'))\n",
    "print('Микросредняя F1 мера - ',f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Попробуем улучшить:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Сначала, я решила попробовать с той же самой лемматизацией. Для того, чтобы улучшить результаты, решила очистить выборку от всего \"мусора\". \n",
    "    + От знаков преппинания, которые есть в *string.punctuation*, с добавлением кавычек-лапок и кавычек-ёлочек, которые встречаются в выборке, а так же добавила троеточие;\n",
    "    + От ссылок. Постаралась рассмотреть все варианты: и http://, и https://, и просто www. ;\n",
    "    + От обращений (начинаются с @);\n",
    "    + От лишних пробелов/переносов/табуляций.\n",
    "\n",
    "На самом деле, даже после такой чистки, в выборку могли просочиться какие-то символы. Не знаю почему, они шпионы какие-то."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def first_normalize(text):\n",
    "    lemmas = []\n",
    "    text = text.lower()\n",
    "    text = re.sub('!|\\#|\\$|%|\\&|\\(|\\)|\\*|\\+|,|-|\\.|\\/|\\:|;|<|=|>|\\?|\\@|\\[|\\]|^|_|`|\\{|\\}|~|«|«|»|\"|…', '', text)\n",
    "    text = re.sub('(http://|https://|www.)[a-zA-z0-9]*? ', '', text)\n",
    "    text = re.sub('[A-Za-z0-9]+', '', text)\n",
    "    text = re.sub('\\s+|\\n|\\t', ' ', text)\n",
    "    tokens = wordpunct_tokenize(text)\n",
    "    for el in tokens:\n",
    "        lemmas.append(morph.parse(el)[0].normal_form)\n",
    "    \n",
    "    clean_lemmas = [lemma for lemma in lemmas \n",
    "                    if lemma not in stops]\n",
    "    \n",
    "    return '  '.join(clean_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data['normalized'] = train_data['text'].apply(first_normalize)\n",
    "test_data['normalized'] = test_data['text'].apply(first_normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(train_data['normalized'].values)\n",
    "\n",
    "X_train = tfidf.transform(train_data['normalized'].values)\n",
    "X_test = tfidf.transform(test_data['normalized'].values)\n",
    "\n",
    "y_train = train_data['label'].values\n",
    "y_test = test_data['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **LogisticRegression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_log = LogisticRegression()\n",
    "clf_log.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf_log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.75      0.55      0.63       902\n",
      "          0       0.62      0.86      0.72       972\n",
      "          1       0.52      0.13      0.21       180\n",
      "\n",
      "avg / total       0.67      0.66      0.64      2054\n",
      "\n",
      "Макросредняя F1 мера -  0.521260884222\n",
      "Микросредняя F1 мера -  0.658227848101\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print('Макросредняя F1 мера - ', f1_score(y_test, y_pred, average='macro'))\n",
    "print('Микросредняя F1 мера - ', f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается, что было:\n",
    "+ Макросредняя F1 мера - 0.517616688856\n",
    "+ Микросредняя F1 мера - 0.671372930867\n",
    "\n",
    "А стало:\n",
    "+ Макросредняя F1 мера -  0.521260884222\n",
    "+ Микросредняя F1 мера -  0.658227848101\n",
    "\n",
    "Не очень:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Потом решила делать с помощью **стемминга**, потому что с лемметизацией вышло как-то не очень:(\n",
    "Стемминг, по сравнению с лемматизацией, легче, потому что лемматизация опирается на словообразование. То есть она определает часть речи и применяет к слову различные способы нормализации. Стемминг же ищет флективную форму в своей таблице поиска, что значительно упрощает и ускоряет работу алгоритма. Кроме того, стемминг хорошо обрабатывает исключения, что в живой речи нам только на руку.\n",
    "\n",
    "+ В предварительной \"очистке\" текста ничего не меняла.\n",
    "+ Для твиттера есть отдельный токанайзер, который хорошо распознаёт смайлики. Используем его!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenizer_words = TweetTokenizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer \n",
    "stemmer = SnowballStemmer('russian')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('!|\\#|\\$|%|\\&|\\(|\\)|\\*|\\+|,|-|\\.|\\/|\\:|;|<|=|>|\\?|\\@|\\[|\\]|^|_|`|\\{|\\}|~|«|«|»|\"|…','',text)\n",
    "    text = re.sub('(http://|www.|https://)[a-zA-z0-9]*? ','', text)\n",
    "    text = re.sub('[A-Za-z0-9]+','',text)\n",
    "    text = re.sub('\\s+|\\n|\\t',' ',text)\n",
    "    stems = [stemmer.stem(token) for token in tokenizer_words.tokenize(text)]\n",
    "    \n",
    "    return '  '.join(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data['normalized'] = train_data['text'].apply(normalize)\n",
    "test_data['normalized'] = test_data['text'].apply(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ TF-IDF и LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(train_data['normalized'].values)\n",
    "\n",
    "X_train = tfidf.transform(train_data['normalized'].values)\n",
    "X_test = tfidf.transform(test_data['normalized'].values)\n",
    "\n",
    "y_train = train_data['label'].values\n",
    "y_test = test_data['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_log = LogisticRegression()\n",
    "clf_log.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf_log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.72      0.71      0.72       902\n",
      "          0       0.68      0.78      0.73       972\n",
      "          1       0.61      0.15      0.24       180\n",
      "\n",
      "avg / total       0.69      0.70      0.68      2054\n",
      "\n",
      "Макросредняя F1 мера -  0.561677964639\n",
      "Микросредняя F1 мера -  0.696202531646\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print('Макросредняя F1 мера - ', f1_score(y_test, y_pred, average='macro'))\n",
    "print('Микросредняя F1 мера - ', f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Красота:)\n",
    "\n",
    "Было:\n",
    "+ Макросредняя F1 мера - 0.517616688856\n",
    "+ Микросредняя F1 мера - 0.671372930867\n",
    "\n",
    "Стало:\n",
    "+ Макросредняя F1 мера -  0.561677964639\n",
    "+ Микросредняя F1 мера -  0.696202531646\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно попробовать улучшить результат и другими способами. Например, использовать другой алгоритм при обучении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **DecisionTree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier()\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = tree_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.62      0.61      0.61       902\n",
      "          0       0.62      0.64      0.63       972\n",
      "          1       0.17      0.17      0.17       180\n",
      "\n",
      "avg / total       0.58      0.58      0.58      2054\n",
      "\n",
      "Макросредняя F1 мера -  0.471131270592\n",
      "Микросредняя F1 мера -  0.583252190847\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print('Макросредняя F1 мера - ', f1_score(y_test, y_pred, average='macro'))\n",
    "print('Микросредняя F1 мера - ', f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат ухудшился."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **RandomForest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest_clf = RandomForestClassifier()\n",
    "forest_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = forest_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.66      0.66      0.66       902\n",
      "          0       0.64      0.73      0.68       972\n",
      "          1       0.41      0.09      0.15       180\n",
      "\n",
      "avg / total       0.63      0.64      0.62      2054\n",
      "\n",
      "Макросредняя F1 мера -  0.495225415658\n",
      "Микросредняя F1 мера -  0.64264849075\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print('Макросредняя F1 мера - ', f1_score(y_test, y_pred, average='macro'))\n",
    "print('Микросредняя F1 мера - ', f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат тоже не очень."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **SGD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = linear_model.SGDClassifier(random_state=6345)\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.71      0.77      0.74       902\n",
      "          0       0.72      0.73      0.73       972\n",
      "          1       0.54      0.26      0.35       180\n",
      "\n",
      "avg / total       0.70      0.71      0.70      2054\n",
      "\n",
      "Макросредняя F1 мера -  0.604001833634\n",
      "Микросредняя F1 мера -  0.707400194742\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print('Макросредняя F1 мера - ', f1_score(y_test, y_pred, average='macro'))\n",
    "print('Микросредняя F1 мера - ', f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Вот это уже лучше:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
